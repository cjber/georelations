import json
import zstandard as zstd
from pathlib import Path
from tqdm.std import tqdm

DATA_DIR = Path("data/reddit_comments")
SUBREDDITS = [
    "unitedkingdom",
    "Britain",
    "England",
    "thenorth",
    "birkenhead",
    "carlisle",
    "Chester",
    "cheshire",
    "cumbria",
    "darwen",
    "fylde",
    "Lancaster_uk",
    "LancashireProblems",
    "Liverpool",
    "liverpoolcity",
    "Manchester",
    "cyclemcr",
    "merseyside",
    "mossley",
    "preston",
    "southport",
    "warrington",
    "wigan",
    "wirral",
    "northeast",
    "alnwick",
    "ashington",
    "durhamuk",
    "morpeth",
    "newcastleupontyne",
    "Northumberland",
    "peterlee",
    "sunderland",
    "teesside",
    "Tyneside",
    "whitleybay",
    "bradford",
    "dewsbury",
    "doncaster",
    "goldsborough",
    "grimsby",
    "harrogate",
    "huddersfield",
    "hull",
    "leeds",
    "leedscycling",
    "lincolnshire",
    "ripponden",
    "scarboroughuk",
    "Sheffield",
    "wakefield",
    "westyorkshire",
    "York",
    "yorkshire",
    "midlands",
    "westmidlands",
    "brum",
    "theblackcountry",
    "coventry",
    "hereford",
    "kenilworth",
    "malvern",
    "shrewsburyuk",
    "shropshire",
    "stafford",
    "staffordshire",
    "warwickshire",
    "wolverhampton",
    "worcester",
    "eastmidlands",
    "beeston",
    "caistor",
    "chesterfielduk",
    "cleethorpes",
    "corby",
    "daventry",
    "derby",
    "derbyshire",
    "duffield",
    "leicester",
    "lincolnshire",
    "louth",
    "northamptonians",
    "nottingham",
    "nottinghamshire",
    "rutland",
    "worksop",
    "westcountry",
    "bath",
    "bournemouth",
    "braunton",
    "bristol",
    "BristolCycling",
    "chippenham",
    "cirencester",
    "cornwall",
    "dartmoor",
    "devonuk",
    "dorset",
    "exeter",
    "exmoor",
    "gloucestershire",
    "plymouth",
    "salisburyUK",
    "saltash",
    "PooleBayCity",
    "swindon",
    "westlynndevon",
    "wiltshire",
    "yeovil",
    "SouthEastEngland",
    "amersham",
    "basingstoke",
    "bexhill",
    "brighton",
    "broadstairs",
    "canterbury",
    "chichester",
    "crawley",
    "egham",
    "graveney",
    "hampshire",
    "hastings",
    "highwycombearea",
    "isleofwight",
    "britishkent",
    "margate",
    "medway",
    "midhurst",
    "miltonkeynes",
    "newforest",
    "oxford",
    "Portsmouth",
    "ramsgate",
    "reading",
    "slough",
    "southampton",
    "Staines",
    "surrey",
    "tadley",
    "thanet",
    "Tunbridgewells",
    "winchesterUK",
    "wokingham",
    "worthing",
    "London",
    "bromley",
    "clapham",
    "croydon",
    "islington",
    "raynes_park",
    "romford",
    "eastanglia",
    "bedfordshire",
    "cambridge",
    "cambridgeshire",
    "cambridgecycling",
    "ely",
    "Essex",
    "fenland",
    "greatyarmouth",
    "harpenden",
    "ipswichuk",
    "kingslynn",
    "luton",
    "maldon",
    "norfolkuk",
    "norwich",
    "rayleigh",
    "stalbans",
    "sudburysuffolk",
    "suffolk",
    "watford",
    "northernireland",
    "Belfast",
    "carrickfergus",
    "derrylondonderry",
    "lisburn",
    "Newry",
    "scotland",
    "aberdeen",
    "annan",
    "arbroath",
    "ayrshire",
    "dundee",
    "DumfriesAndGalloway",
    "Edinburgh",
    "eastkilbride",
    "elginscotland",
    "falkirk",
    "fife",
    "Glasgow",
    "glencoe",
    "inverness",
    "irvinescotland",
    "kettins",
    "kilmarnock",
    "lanarkshire",
    "orkney",
    "shetland",
    "stirlingscotland",
    "stornoway",
    "westernisles",
    "whitburn",
    "Wales",
    "HistoryWales",
    "abergavenny",
    "abertillery",
    "aberystwyth",
    "bangor",
    "bridgend",
    "builthwells",
    "cardiff",
    "flintshire",
    "holyhead",
    "newportSW",
    "pembrokeshire",
    "porthcawl",
    "southwales",
    "swansea",
    "wrexham",
    "isleofman",
    "guernsey",
]


class Zreader:
    def __init__(self, file, chunk_size=16384):
        """Init method"""
        self.fh = open(file, "rb")
        self.chunk_size = chunk_size
        self.dctx = zstd.ZstdDecompressor(max_window_size=2_147_483_648)
        self.reader = self.dctx.stream_reader(self.fh)
        self.buffer = ""

    def readlines(self):
        """Generator method that creates an iterator for each line of JSON"""
        while True:
            chunk = self.reader.read(self.chunk_size).decode()
            if not chunk:
                break
            lines = (self.buffer + chunk).split("\n")

            yield from lines[:-1]
            self.buffer = lines[-1]


reader = Zreader("data/reddit_comments/RC_2021-06.zst", chunk_size=8192)

comments = []
with open(DATA_DIR / "comments.jsonl", "w") as f:
    # 4 billion estimated comments
    for line in tqdm(reader.readlines(), total=4_000_000_000):
        obj = json.loads(line)
        if obj["subreddit"] in SUBREDDITS:
            json.dump(obj, f)
            f.write("\n")
